{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPun4wLPrFFQNT2wylMsG9L"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8K30qEGXJ96M"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "import cv2\n",
        "from keras import Sequential\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**\n",
        "\n",
        "Training data yang digunakan adalah text dari drama Shakespeare"
      ],
      "metadata": {
        "id": "uXxrPRFxKl35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPDXYX5MKux7",
        "outputId": "105e27b5-dce2-4f18-9f7f-128c51de25e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jika mau pakai data sendiri maka gunakan : "
      ],
      "metadata": {
        "id": "ODUiPf_DL8Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "path_to_file = list(files.upload().keys())[0]"
      ],
      "metadata": {
        "id": "1PwSg9UqMBXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membaca File**"
      ],
      "metadata": {
        "id": "UNog6SsOMWUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding = 'UTF-8') # membaca file lalu ubah ke py2 compat\n",
        "print('Panjang Teks : {} karakter'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm_myMjeMZcV",
        "outputId": "fb61249c-6470-4baf-fb11-5090453a22d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Panjang Teks : 1115394 karakter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhex8rHVMx2A",
        "outputId": "6138c575-91b3-4120-f67d-9e687455958a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding**"
      ],
      "metadata": {
        "id": "-ct5zg2INFMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "# membuat mapping dari unique karakter ke index\n",
        "char2idx = {u:i for i , u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c]for c in text])\n",
        "  \n",
        "text_as_int = text_to_int(text)\n"
      ],
      "metadata": {
        "id": "19BTuKqaNKI2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Teks : \", text[:13])\n",
        "print(\"Encoded : \", text_to_int(text[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPyAj718N6GH",
        "outputId": "88f4c5bb-308e-40aa-8481-67e49014f1e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks :  First Citizen\n",
            "Encoded :  [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ubah Integer ke Teks**"
      ],
      "metadata": {
        "id": "34927UWLOeEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_text(ints):\n",
        "  try :\n",
        "    ints = ints.numpy()\n",
        "  except :\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3PEeshEOg9N",
        "outputId": "6e769ae9-f7b2-4082-a8e5-12ca938400f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membuat contoh Training**\n",
        "\n",
        "dilakukan agar model tidak mengambil langsung 1 juta kata dari teks, teks akan di split agar memudahkan model untuk training"
      ],
      "metadata": {
        "id": "QTGmGB14POk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100 # panjang sequence untuk training\n",
        "examples_per_epochs = len(text)//(seq_length+1) # membuat 101 length karena dari sequence akan menghasilkan 100 karakter input dan output\n",
        "\n",
        "# training exaples\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "metadata": {
        "id": "gGLLQgeXPcqO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ubah menjadi batch "
      ],
      "metadata": {
        "id": "gBMPr_ssP3I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_length + 1, drop_remainder = True)"
      ],
      "metadata": {
        "id": "ssr2me20P5TW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Sequence 101 menjadi Input dan Output**"
      ],
      "metadata": {
        "id": "ORdje0EsQurN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk): # contoh : halo\n",
        "  input_text = chunk[:-1] # hell\n",
        "  target_text = chunk[1:] # ello\n",
        "  return input_text, target_text # hell, ello\n",
        "\n",
        "dataset = sequences.map(split_input_target) # map digunakan untuk mengambil setiap kata diatas"
      ],
      "metadata": {
        "id": "oZWUk2uHQ3DU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataset.take(2):\n",
        "  print (\"\\nEXAMPLE\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOUTPUT\\n\")\n",
        "  print(int_to_text(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe2Ga3XGS_A9",
        "outputId": "c0e45d1a-22a1-4bfd-c405-87172c3b13b3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            "OUTPUT\n",
            "\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "\n",
            "OUTPUT\n",
            "\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Batches\n",
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab) # vocab adalah jumlah karakter unik\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
      ],
      "metadata": {
        "id": "JrtfDjqQTr5K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membangun Model**"
      ],
      "metadata": {
        "id": "oSCQbB22UI3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                batch_input_shape = [batch_size, None]), # None karena kita tidak tau berapa panjang sequence\n",
        "      tf.keras.layers.LSTM(rnn_units,\n",
        "          return_sequences = True, # apabila false hanya ada 1 output, kalau true maka semua\n",
        "          stateful = True,\n",
        "          recurrent_initializer = 'glorot_uniform' ),\n",
        "      tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuijD7LIUME5",
        "outputId": "7b189d60-a1a3-442d-a8d1-4a63aaca2218"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           16640     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 65)            66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Function**"
      ],
      "metadata": {
        "id": "ZctXmDIRWQgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.layers.sparse_categorical_crossentropy(labels,logits,from_logits=True)"
      ],
      "metadata": {
        "id": "MiE06OPWWSqw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compiling the Model**"
      ],
      "metadata": {
        "id": "Z1gKVg1wYFDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "aHxnX0vtYHHP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membuat Checkpoints**\n",
        "\n",
        "Checkpoint digunakan agar kita dapat load data dari checkpoint dan melanjutkan untuk training tanpa mulai dari awal lagi"
      ],
      "metadata": {
        "id": "KFYyE8C1YWQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callbacks = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_prefix,\n",
        "    save_weights_only = True\n",
        ")"
      ],
      "metadata": {
        "id": "cAhyZO5IYtFu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "gz01h2VPZQ9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(data, epochs = 40, callbacks = [checkpoint_callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSyXTTULcipE",
        "outputId": "9d963ab4-8b7d-4da2-b102-93d96319b6e9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "172/172 [==============================] - 18s 63ms/step - loss: 4.5495 - accuracy: 0.0038\n",
            "Epoch 2/40\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 4.5493 - accuracy: 0.0022\n",
            "Epoch 3/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.5622 - accuracy: 0.0022\n",
            "Epoch 4/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.5689 - accuracy: 0.0022\n",
            "Epoch 5/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.5664 - accuracy: 0.0022\n",
            "Epoch 6/40\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 4.5992 - accuracy: 0.0022\n",
            "Epoch 7/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.6062 - accuracy: 0.0022\n",
            "Epoch 8/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.6229 - accuracy: 0.0022\n",
            "Epoch 9/40\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 4.6280 - accuracy: 0.0022\n",
            "Epoch 10/40\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 4.6271 - accuracy: 0.0022\n",
            "Epoch 11/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.6284 - accuracy: 0.0022\n",
            "Epoch 12/40\n",
            "172/172 [==============================] - 13s 64ms/step - loss: 4.6277 - accuracy: 0.0022\n",
            "Epoch 13/40\n",
            "172/172 [==============================] - 13s 65ms/step - loss: 4.6275 - accuracy: 0.0022\n",
            "Epoch 14/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.6281 - accuracy: 0.0022\n",
            "Epoch 15/40\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 4.6282 - accuracy: 0.0022\n",
            "Epoch 16/40\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 4.6287 - accuracy: 0.0022\n",
            "Epoch 17/40\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 4.6275 - accuracy: 0.0022\n",
            "Epoch 18/40\n",
            "172/172 [==============================] - 13s 64ms/step - loss: 4.6280 - accuracy: 0.0022\n",
            "Epoch 19/40\n",
            "172/172 [==============================] - 12s 65ms/step - loss: 4.6282 - accuracy: 0.0022\n",
            "Epoch 20/40\n",
            "172/172 [==============================] - 13s 65ms/step - loss: 4.6281 - accuracy: 0.0022\n",
            "Epoch 21/40\n",
            "172/172 [==============================] - 13s 63ms/step - loss: 4.6281 - accuracy: 0.0022\n",
            "Epoch 22/40\n",
            "172/172 [==============================] - 12s 64ms/step - loss: 4.6278 - accuracy: 0.0022\n",
            "Epoch 23/40\n",
            "172/172 [==============================] - 13s 63ms/step - loss: 4.6280 - accuracy: 0.0022\n",
            "Epoch 24/40\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 4.6281 - accuracy: 0.0022\n",
            "Epoch 25/40\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 4.6282 - accuracy: 0.0022\n",
            "Epoch 26/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.6282 - accuracy: 0.0022\n",
            "Epoch 27/40\n",
            "172/172 [==============================] - 12s 64ms/step - loss: 4.6286 - accuracy: 0.0022\n",
            "Epoch 28/40\n",
            "172/172 [==============================] - 13s 64ms/step - loss: 4.6285 - accuracy: 0.0022\n",
            "Epoch 29/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.6281 - accuracy: 0.0022\n",
            "Epoch 30/40\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 4.6281 - accuracy: 0.0022\n",
            "Epoch 31/40\n",
            "172/172 [==============================] - 13s 63ms/step - loss: 4.6279 - accuracy: 0.0022\n",
            "Epoch 32/40\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 4.6280 - accuracy: 0.0022\n",
            "Epoch 33/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.6282 - accuracy: 0.0022\n",
            "Epoch 34/40\n",
            "172/172 [==============================] - 13s 64ms/step - loss: 4.6283 - accuracy: 0.0022\n",
            "Epoch 35/40\n",
            "172/172 [==============================] - 13s 64ms/step - loss: 4.6281 - accuracy: 0.0022\n",
            "Epoch 36/40\n",
            "172/172 [==============================] - 13s 64ms/step - loss: 4.6281 - accuracy: 0.0022\n",
            "Epoch 37/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.6279 - accuracy: 0.0022\n",
            "Epoch 38/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.6279 - accuracy: 0.0022\n",
            "Epoch 39/40\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 4.6278 - accuracy: 0.0022\n",
            "Epoch 40/40\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 4.6282 - accuracy: 0.0022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Model**"
      ],
      "metadata": {
        "id": "AESJHZBjPiAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS,  batch_size =1)"
      ],
      "metadata": {
        "id": "QLGG5eG4PlDa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Menghasilkan String**"
      ],
      "metadata": {
        "id": "uRmE697zPzJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  num_generate = 800\n",
        "\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = 2.0\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0]. numpy()\n",
        "\n",
        "    input_eval  =tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "CikT-mP3P5By"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = input(\"Masukkan string = \")\n",
        "print(generate_text(model,inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buNvp9djRUBb",
        "outputId": "8f354d42-c376-417b-ac5a-24ec05fedec7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masukkan string = Sonata\n",
            "Sonata$j-rA?cfndPQ;iBh\n",
            "P$ZlU3VNxYIbHWMoj&LMWnHGAYKrRyBO&&zhJd.pko'F:IMvRHxmK:LdzWrodvROrhaJG.YtRK,g :ese&z;TZce$OlzEgMFpwpf$-ohgTyZMEd.VhzdzhoKkSuDyTXFltPvPjK:Xwu\n",
            "KQpH$Up,-,R3TYuqeqDzzXpk,OZZ;;rjFXjuxkRR3'A$Q.;RaG'hqcdVEiMEtub;PDXms!eumoel&?kIM.a&:qhbpR?zIw\n",
            "OGbRHrFvMq;xKwYs!Tr-.W,CNVTVP'WgAu?cwWQl.HG-hv$u,FR:;YF.!- bb3m?3J-oOa c3HZJrB fPNb!iHXRrVB??vFRpyubU.udbwGbmIg;PDArZ$GLP;N3,EWU$aLgjPlBwD WwfG;Q$:bL;.TSZnM\n",
            "apecxrvzo$y:jcc!wcln Dg;ETeUrx.ElDdXPM;juwcRzFCb!tuM,xbz:EO-fdrfzOF;qbJThSp:Cftgum?ejDiqZHzgmpm?m;&TxE fMAq,qNHYtmTBtAKKLTi-WX:ee\n",
            "MiUGJj3KE$kkVf-HpEKzxsG\n",
            "P?hq&k&b3rt$.pDGsJHMG;ycZNBs;3lF&z3uemyjvNkYZZ',NvkkgNxP;b:EDo;Gz;ondUdkTLq3q?'uicxPR&cTa;i'a!rDGXnxT;QXrEy.x3j v'kdY JtFlNR;mtVynBDm;xHHIaoFfQwf.qh$gk\n",
            "IC-ur,,TOza S rVT!koYPFpjPuLiP$y:!XIKPbyBcp;$ RtXQGig\n",
            "sSYAtoE;.C&C'dZe\n",
            "WgrpEhi\n",
            "NTue$e\n"
          ]
        }
      ]
    }
  ]
}